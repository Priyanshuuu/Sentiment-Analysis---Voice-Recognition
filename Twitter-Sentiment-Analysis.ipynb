{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\PRIYANSHU\n",
      "[nltk_data]     PANDEY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##adding list of stopwords and punctuations.\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stops=set(stopwords.words('english'))\n",
    "punct=list(string.punctuation)\n",
    "stops.update(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=pd.read_csv('twitter_x_y_train.csv')\n",
    "testdata=pd.read_csv('twitter_x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=traindata['text']\n",
    "x_test_data=testdata['text']\n",
    "y_train_data=traindata['airline_sentiment']\n",
    "#total_data=traindata.append(testdata,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "\n",
    "def  Remove_stop_words(x):\n",
    "    l=len(x)\n",
    "    #print(l)\n",
    "    y=[]\n",
    "   \n",
    "    for i in range(l):\n",
    "        if x[i] not in stops :\n",
    "            y.append(x[i])\n",
    "    #print(len(y))\n",
    "    return y\n",
    "\n",
    "def lower_casing(words): \n",
    "    text=[]\n",
    "    for i in words :\n",
    "        text.append(i.lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "def adding(b):\n",
    "    \n",
    "    txt=''\n",
    "    for i in range(len(b)):\n",
    "        txt+=' '+b[i]\n",
    "    textdocument.append(txt)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_documents = [\"\".join(x_t[i]) for i in range(len(x_t))]\n",
    "\n",
    "def prep(b):\n",
    "    z=word_tokenize(b)\n",
    "    #print(z)\n",
    "    for i in range(2):\n",
    "        z.remove(z[0])\n",
    "    #print(z)\n",
    "    z=lower_casing(z)\n",
    "    z=Remove_stop_words(z)\n",
    "    return z\n",
    "\n",
    "textdocument=[]\n",
    "for i in range(len(text_documents)):\n",
    "    b=prep(text_documents[i])\n",
    "    adding(b)\n",
    "\n",
    "df=pd.DataFrame(textdocument)\n",
    "x_train_data=df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scheduled morning 2 days fact yes..not sure e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seeing workers time time going beyond love fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flew ord miami back great crew service legs t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dultch97 's horse radish üò§üê¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flight ord delayed air force one last flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>load us flying sardine knew pilots 2 hours la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stock response delays frustrating poor cust s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'d nice hoping rack enough miles take trip se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frankly worse customer service ever problems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yeah haha never one 's expensive üòÇüòÇ much fun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mco- gt dca flight almost full people screwed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'s easiest way get ticket receipt get one che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>love changes lounge cheese veggies olives add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>receive bad customer service ended spending s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'re killing sche flight board 3 min mine arri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8 weeks refund ticket 0372389047497 totally u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>private msg provide details ... u really need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rt jetblue fleet 's fleek http //t.co/413gial0yl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>info flight 704 sju jfk already delayed 2 1/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'ve tried less 8 times today get touch servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>new problem ... wrong last name reservation a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>possible chance swa bringing back service lga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>americanair runs show airport boarding pass s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>computers stopped giving updates took flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>good fly united businessfirst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>flying msp dxb child turn 2 trip buy return t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loves cancelled flightling tickets telling cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ord waited 20 min crew members left gate item...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jason 108639 gate 3 san made afternoon southw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>everything sorted thanks help excited get hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>could tell bag would accepted personal item b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>yo need new website really badly day age ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>theellenshow imaginedragons kdepetro313 .what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>right amp away ‚úàÔ∏èüåû</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>two dozen back line see single csr reflight b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>would charge money transfer points someone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>possible earn dividend miles passenger even p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>jetblue fleet 's fleek http //t.co/1g9rnmyuqe ‚Äù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>phone line call n't affected `` bad weather '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>never seen incompetency gate agent years busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>f623 den phx impressive lack concern 1hr+ lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>clients 11 hr layover iah day claim amp reche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>even change could made online- instructed cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ca n't claim `` weather '' hardworking crew p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>finally called ca n't get met seattle refund ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>played bizarre `` safety '' video 've ever se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>'m sure messaging part right please let know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>booked 8th ... save emergency exit ... got ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>try get customers destinations help get anoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>catch name sure jason know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>yet another delay/missed connection ... .and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>access dividend miles week automated phone ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>direct flights belfast intl newark resume win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>lgjw7b voluntarily rerouted 1st leg journey e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>nashville airport runways open appears southw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>flight plans delayed tuesday due computer crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>unbelievable ... thank much destinationdragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>big surprise nogate waiting plane fucken issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tough night two 90 minute calls hold delayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>'s hard stay upset someone least try show rem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0    scheduled morning 2 days fact yes..not sure e...\n",
       "1    seeing workers time time going beyond love fl...\n",
       "2    flew ord miami back great crew service legs t...\n",
       "3                         dultch97 's horse radish üò§üê¥\n",
       "4    flight ord delayed air force one last flight ...\n",
       "5    load us flying sardine knew pilots 2 hours la...\n",
       "6    stock response delays frustrating poor cust s...\n",
       "7    'd nice hoping rack enough miles take trip se...\n",
       "8    frankly worse customer service ever problems ...\n",
       "9    yeah haha never one 's expensive üòÇüòÇ much fun ...\n",
       "10   mco- gt dca flight almost full people screwed...\n",
       "11   's easiest way get ticket receipt get one che...\n",
       "12   love changes lounge cheese veggies olives add...\n",
       "13   receive bad customer service ended spending s...\n",
       "14   're killing sche flight board 3 min mine arri...\n",
       "15   8 weeks refund ticket 0372389047497 totally u...\n",
       "16   private msg provide details ... u really need...\n",
       "17   rt jetblue fleet 's fleek http //t.co/413gial0yl\n",
       "18   info flight 704 sju jfk already delayed 2 1/2...\n",
       "19   've tried less 8 times today get touch servic...\n",
       "20   new problem ... wrong last name reservation a...\n",
       "21   possible chance swa bringing back service lga...\n",
       "22   americanair runs show airport boarding pass s...\n",
       "23   computers stopped giving updates took flight ...\n",
       "24                      good fly united businessfirst\n",
       "25   flying msp dxb child turn 2 trip buy return t...\n",
       "26   loves cancelled flightling tickets telling cu...\n",
       "27   ord waited 20 min crew members left gate item...\n",
       "28   jason 108639 gate 3 san made afternoon southw...\n",
       "29   everything sorted thanks help excited get hom...\n",
       "..                                                ...\n",
       "70   could tell bag would accepted personal item b...\n",
       "71       yo need new website really badly day age ...\n",
       "72   theellenshow imaginedragons kdepetro313 .what...\n",
       "73                                 right amp away ‚úàÔ∏èüåû\n",
       "74   two dozen back line see single csr reflight b...\n",
       "75         would charge money transfer points someone\n",
       "76   possible earn dividend miles passenger even p...\n",
       "77    jetblue fleet 's fleek http //t.co/1g9rnmyuqe ‚Äù\n",
       "78   phone line call n't affected `` bad weather '...\n",
       "79   never seen incompetency gate agent years busi...\n",
       "80   f623 den phx impressive lack concern 1hr+ lat...\n",
       "81   clients 11 hr layover iah day claim amp reche...\n",
       "82   even change could made online- instructed cal...\n",
       "83   ca n't claim `` weather '' hardworking crew p...\n",
       "84   finally called ca n't get met seattle refund ...\n",
       "85   played bizarre `` safety '' video 've ever se...\n",
       "86   'm sure messaging part right please let know ...\n",
       "87   booked 8th ... save emergency exit ... got ta...\n",
       "88   try get customers destinations help get anoth...\n",
       "89                         catch name sure jason know\n",
       "90   yet another delay/missed connection ... .and ...\n",
       "91   access dividend miles week automated phone ke...\n",
       "92   direct flights belfast intl newark resume win...\n",
       "93   lgjw7b voluntarily rerouted 1st leg journey e...\n",
       "94   nashville airport runways open appears southw...\n",
       "95    flight plans delayed tuesday due computer crash\n",
       "96     unbelievable ... thank much destinationdragons\n",
       "97   big surprise nogate waiting plane fucken issu...\n",
       "98   tough night two 90 minute calls hold delayed ...\n",
       "99   's hard stay upset someone least try show rem...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "xtrain,xtest,ytrain,ytest=model_selection.train_test_split(x_train_data,y_train_data,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##now we aim to remove # ,@ and other numeric words\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf=TfidfVectorizer(max_features=3000,ngram_range=(1,2),stop_words=stops,analyzer='word', max_df = 0.8, lowercase = True, use_idf = True, smooth_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=tf_idf.fit_transform(xtrain,ytrain)\n",
    "test_features=tf_idf.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 258)\t0.30296941675610717\n",
      "  (0, 1193)\t0.3332907651807398\n",
      "  (0, 1224)\t0.18040129971312488\n",
      "  (0, 1567)\t0.24160396713659313\n",
      "  (0, 2011)\t0.3843811113510374\n",
      "  (0, 2497)\t0.4033504276835335\n",
      "  (0, 2735)\t0.31489146166591175\n",
      "  (0, 2736)\t0.42426660280469985\n",
      "  (0, 2786)\t0.2341888024654847\n",
      "  (0, 2893)\t0.24852788197639986\n",
      "  (1, 258)\t0.25099671451981115\n",
      "  (1, 464)\t0.31329073012198094\n",
      "  (1, 465)\t0.24297942341444637\n",
      "  (1, 470)\t0.2959593602851063\n",
      "  (1, 965)\t0.30003257511826303\n",
      "  (1, 1040)\t0.10600508166074951\n",
      "  (1, 1064)\t0.329655196576054\n",
      "  (1, 1117)\t0.2959593602851063\n",
      "  (1, 1129)\t0.176746551753369\n",
      "  (1, 1329)\t0.20015816320844831\n",
      "  (1, 1686)\t0.21566744084242584\n",
      "  (1, 1873)\t0.18303699686317798\n",
      "  (1, 1875)\t0.35148604939945566\n",
      "  (1, 2670)\t0.34617545478905765\n",
      "  (2, 365)\t0.2852855376327282\n",
      "  :\t:\n",
      "  (8231, 1040)\t0.25388535438400045\n",
      "  (8231, 1214)\t0.22552888181939454\n",
      "  (8231, 1218)\t0.4001591353198312\n",
      "  (8231, 1354)\t0.4001591353198312\n",
      "  (8231, 1800)\t0.25482897802712323\n",
      "  (8231, 1992)\t0.42090982250455133\n",
      "  (8232, 687)\t0.22467591786605431\n",
      "  (8232, 691)\t0.2411834052265265\n",
      "  (8232, 1567)\t0.26433987781726287\n",
      "  (8232, 2376)\t0.2112772993075854\n",
      "  (8232, 2386)\t0.44795501528822174\n",
      "  (8232, 2611)\t0.6666017384683541\n",
      "  (8232, 2655)\t0.36306480869994484\n",
      "  (8233, 463)\t0.6080594160093681\n",
      "  (8233, 482)\t0.4607538824083632\n",
      "  (8233, 1946)\t0.3173693415873019\n",
      "  (8233, 2985)\t0.5632462227733169\n",
      "  (8234, 598)\t0.40810171068591794\n",
      "  (8234, 735)\t0.2853424079267753\n",
      "  (8234, 1294)\t0.2624121425850746\n",
      "  (8234, 1918)\t0.33204623125709687\n",
      "  (8234, 2146)\t0.3978956735013307\n",
      "  (8234, 2421)\t0.46459416932095876\n",
      "  (8234, 2648)\t0.37338583565352834\n",
      "  (8234, 2806)\t0.24358197856338445\n",
      "\n",
      "  (0, 154)\t0.3499515581010589\n",
      "  (0, 569)\t0.29376959614061043\n",
      "  (0, 1904)\t0.2628834856351599\n",
      "  (0, 2451)\t0.29376959614061043\n",
      "  (0, 2534)\t0.33466808279583365\n",
      "  (0, 2661)\t0.3790247578623741\n",
      "  (0, 2714)\t0.2393474117052211\n",
      "  (0, 2715)\t0.3790247578623741\n",
      "  (0, 2893)\t0.22626689231294994\n",
      "  (0, 2903)\t0.3577972594854028\n",
      "  (1, 167)\t0.35411460806607153\n",
      "  (1, 213)\t0.25989157738993557\n",
      "  (1, 575)\t0.2176292712010852\n",
      "  (1, 825)\t0.43726302520619537\n",
      "  (1, 843)\t0.3178705505820486\n",
      "  (1, 1463)\t0.2205354201280135\n",
      "  (1, 1464)\t0.2205354201280135\n",
      "  (1, 1635)\t0.33640200530136366\n",
      "  (1, 2286)\t0.32777764197764475\n",
      "  (1, 2326)\t0.38675552707023697\n",
      "  (2, 209)\t0.2063807506584521\n",
      "  (2, 246)\t0.31820588561382845\n",
      "  (2, 278)\t0.2777157586378117\n",
      "  (2, 450)\t0.1845256118059988\n",
      "  (2, 455)\t0.3315071282357406\n",
      "  :\t:\n",
      "  (2741, 2818)\t0.34065615880118216\n",
      "  (2742, 381)\t0.39196022370001293\n",
      "  (2742, 2242)\t0.47808768981514477\n",
      "  (2742, 2520)\t0.2826760915716138\n",
      "  (2742, 2682)\t0.3013082618991165\n",
      "  (2742, 2760)\t0.40421767636148287\n",
      "  (2742, 2890)\t0.5326490144234826\n",
      "  (2743, 153)\t0.3630340563977905\n",
      "  (2743, 176)\t0.22766093405689547\n",
      "  (2743, 517)\t0.30747148492508236\n",
      "  (2743, 551)\t0.38901528651187517\n",
      "  (2743, 1202)\t0.285454375081788\n",
      "  (2743, 1861)\t0.32576401033854857\n",
      "  (2743, 2102)\t0.3114356051958726\n",
      "  (2743, 2153)\t0.3338165127374167\n",
      "  (2743, 2217)\t0.2734296216933427\n",
      "  (2743, 2670)\t0.19522795798999404\n",
      "  (2743, 2877)\t0.24818432902254606\n",
      "  (2744, 381)\t0.3963695932568322\n",
      "  (2744, 1442)\t0.27455698421275276\n",
      "  (2744, 1617)\t0.34364272172163607\n",
      "  (2744, 2066)\t0.2792791176773124\n",
      "  (2744, 2164)\t0.4592445052505487\n",
      "  (2744, 2315)\t0.43720314198610155\n",
      "  (2744, 2427)\t0.41154630266010056\n"
     ]
    }
   ],
   "source": [
    "print(train_features)\n",
    "print()\n",
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 1), match='@'>\n"
     ]
    }
   ],
   "source": [
    "result = re.match(r'@', '@himanish98 i says lets party! but we dont like that @himanish98')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "##doing for svm classifier\n",
    "svc=SVC()\n",
    "svc.fit(train_features,ytrain)\n",
    "Ac_svc = svc.score(test_features,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#doing for random-forest-classifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(train_features,ytrain)\n",
    "Ac_rfc = rfc.score(test_features,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing for MultinomialNaiveBayes\n",
    "nb=MultinomialNB()\n",
    "nb.fit(train_features,ytrain)\n",
    "Ac_nb = nb.score(test_features,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(C=1)\n",
    "clf.fit(train_features,ytrain)\n",
    "Ac_LG = clf.score(test_features,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "G:\\ANACONDA3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = LogisticRegression()\n",
    "grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "abc = GridSearchCV(clf, grid) \n",
    "abc.fit(train_features, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627200971463266"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @AmericanAir In car gng to DFW. Pulled over 1h...\n",
       "1    @AmericanAir after all, the plane didn‚Äôt land ...\n",
       "2    @SouthwestAir can't believe how many paying cu...\n",
       "3    @USAirways I can legitimately say that I would...\n",
       "4    @AmericanAir still no response from AA. great ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using logistic regression paramter finally\n",
    "x_test_data1=tf_idf.transform(x_test_data)\n",
    "y_predict=nb.predict(x_test_data1)\n",
    "np.savetxt('Predictions-Project.csv',y_predict,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=len(ytrain)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizex=0\n",
    "sizey=0\n",
    "sizez=0\n",
    "\n",
    "total=len(y_train_data)\n",
    "for i in range(total):\n",
    "    if y_train_data[i]=='positive':\n",
    "        sizex+=1\n",
    "    elif y_train_data[i]=='negative':\n",
    "        sizey+=1\n",
    "    else:\n",
    "        sizez+=1\n",
    "        \n",
    "#print(sizex)\n",
    "#print(sizey)\n",
    "#print(sizez)\n",
    "\n",
    "#print(sizex+sizey)\n",
    "#print(total)\n",
    "#len(y_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which represent a negative feed back\n"
     ]
    }
   ],
   "source": [
    "x_test_data1=tf_idf.transform(x_test_data.head(1))\n",
    "y_predict=nb.predict(x_test_data1)\n",
    "b='which represent a '+ y_predict[0] +' feed back'\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from threading import Thread\n",
    "import pyglet\n",
    "def playsound(command):\n",
    "    root = Tk()\n",
    "    app = Frame(root)\n",
    "    app.pack(side='bottom')\n",
    "\n",
    "    player = pyglet.media.Player()\n",
    "    music_file = pyglet.media.load(command)\n",
    "\n",
    "    def startPlaying():\n",
    "        player.queue(music_file)\n",
    "        player.play()\n",
    "        pyglet.app.run()\n",
    "\n",
    "    def playSound():\n",
    "        global sound_thread \n",
    "        sound_thread = Thread(target=startPlaying)\n",
    "        sound_thread.start()\n",
    "\n",
    "    button1 = Button(app, text=\"Listen Your Response\", command=playSound)\n",
    "    button1.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "    pyglet.app.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import re\n",
    "import webbrowser\n",
    "import smtplib\n",
    "import requests\n",
    "from weather import Weather\n",
    "import pyglet\n",
    "\n",
    "def talkToMe(audio):\n",
    "    \"speaks audio passed as argument\"\n",
    "\n",
    "    print(audio)\n",
    "    for line in audio.splitlines():\n",
    "        os.system(\"say \" + audio)\n",
    "\n",
    "    #  use the system's inbuilt say command instead of mpg123\n",
    "    #  text_to_speech = gTTS(text=audio, lang='en')\n",
    "    #  text_to_speech.save('audio.mp3')\n",
    "    #  os.system('mpg123 audio.mp3')\n",
    "\n",
    "\n",
    "def myCommand():\n",
    "    \"listens for commands\"\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print('Ready...')\n",
    "        r.pause_threshold = 1\n",
    "        r.adjust_for_ambient_noise(source, duration=1)\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        command = r.recognize_google(audio,language=\"en-IN\").lower()\n",
    "        z='You said: ' + command + '\\n'\n",
    "        print(z)\n",
    "        \n",
    "        language = 'en'\n",
    "       \n",
    "\n",
    "      \n",
    "        list_of_predifined_queries=['open reddit','open website','what\\'s up','weather forecast in','ok tell me a joke','who is your owner','how are you']\n",
    "        \n",
    "        if command not in list_of_predifined_queries:\n",
    "            x.drop(x.index[0],inplace=True)\n",
    "            x_test_data.loc[0]=command\n",
    "            x_test_data1=tf_idf.transform(x_test_data.head(1)) \n",
    "            y_predict=nb.predict(x_test_data1)\n",
    "            \n",
    "            z=' This will consider  as  a  '+ y_predict[0] +' feed back!'\n",
    "\n",
    "            myobj = gTTS(text=z, lang=language, slow=False) \n",
    "            myobj.save(\"currentvoice.mp3\")\n",
    "\n",
    "            so='currentvoice.mp3'\n",
    "            playsound(so)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    #loop back to continue to listen for commands if unrecognizable speech is received\n",
    "    except sr.UnknownValueError:\n",
    "        print('Your last command couldn\\'t be heard')\n",
    "        command = myCommand();\n",
    "\n",
    "    return command\n",
    "\n",
    "\n",
    "def assistant(command):\n",
    "    \"if statements for executing commands\"\n",
    "\n",
    "    if 'open reddit' in command:\n",
    "        reg_ex = re.search('open reddit (.*)', command)\n",
    "        url = 'https://www.reddit.com/'\n",
    "        if reg_ex:\n",
    "            subreddit = reg_ex.group(1)\n",
    "            url = url + 'r/' + subreddit\n",
    "        webbrowser.open(url)\n",
    "        print('Done!')\n",
    "\n",
    "    elif 'open website' in command:\n",
    "        reg_ex = re.search('open website (.+)', command)\n",
    "        if reg_ex:\n",
    "            domain = reg_ex.group(1)\n",
    "            url = 'https://www.' + domain\n",
    "            webbrowser.open(url)\n",
    "            print('Done!')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    elif 'what\\'s up' in command:\n",
    "        talkToMe('Just doing my thing')\n",
    "        \n",
    "    elif 'how are you' in command:\n",
    "        talkToMe('I am fine !')\n",
    "    \n",
    "    elif 'who is your owner' in command:\n",
    "        talkToMe('My owner name is Mr. Priyanshu.')\n",
    "    \n",
    "    elif 'where is ishita' in command:\n",
    "        talkToMe('she is in digital communication  lab')\n",
    "        \n",
    "        \n",
    "    elif 'tell me something about you' in command:\n",
    "        talkToMe('I am created for the hackathon competition which is organise by hackcbs .')\n",
    "        \n",
    "    elif 'ok tell me a joke' in command:\n",
    "        res = requests.get(\n",
    "                'https://icanhazdadjoke.com/',\n",
    "                headers={\"Accept\":\"application/json\"}\n",
    "                )\n",
    "        if res.status_code == requests.codes.ok:\n",
    "            talkToMe(str(res.json()['joke']))\n",
    "        else:\n",
    "            talkToMe('oops!I ran out of jokes')\n",
    "\n",
    "    elif 'current weather in' in command:\n",
    "        reg_ex = re.search('current weather in (.*)', command)\n",
    "        if reg_ex:\n",
    "            city = reg_ex.group(1)\n",
    "            weather = Weather()\n",
    "            location = weather.lookup_by_location(city)\n",
    "            condition = location.condition()\n",
    "            talkToMe('The Current weather in %s is %s The tempeture is %.1f degree' % (city, condition.text(), (int(condition.temp())-32)/1.8))\n",
    "\n",
    "    elif 'weather forecast in' in command:\n",
    "        reg_ex = re.search('weather forecast in (.*)', command)\n",
    "        if reg_ex:\n",
    "            city = reg_ex.group(1)\n",
    "            weather = Weather()\n",
    "            location = weather.lookup_by_location(city)\n",
    "            forecasts = location.forecast()\n",
    "            print(forecasts)\n",
    "            for forecast in forecasts:\n",
    "                talkToMe('On %s will it %s. The maximum temperture will be %.1f degree.'\n",
    "                         'The lowest temperature will be %.1f degrees.' % (forecast.date, forecast.text, (int(forecast.high)-32)/1.8, (int(forecast.low)-32)/1.8))\n",
    "\n",
    "\n",
    "    elif 'email' in command:\n",
    "        talkToMe('Who is the recipient?')\n",
    "        recipient = myCommand()\n",
    "\n",
    "        if 'ishita' in recipient:\n",
    "            talkToMe('What should I say?')\n",
    "            content = myCommand()\n",
    "\n",
    "            #init gmail SMTP\n",
    "            mail = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "\n",
    "            #identify to server\n",
    "            mail.ehlo()\n",
    "\n",
    "            #encrypt session\n",
    "            mail.starttls()\n",
    "\n",
    "            #login\n",
    "            mail.login('username', 'password')\n",
    "\n",
    "            #send message\n",
    "            mail.sendmail('John Fisher', 'JARVIS2.0@protonmail.com', content)\n",
    "\n",
    "            #end mail connection\n",
    "            mail.close()\n",
    "\n",
    "            talkToMe('Email sent.')\n",
    "\n",
    "        else:\n",
    "            talkToMe('I don\\'t know what you mean!')\n",
    "\n",
    "\n",
    "talkToMe('I am ready for your command')\n",
    "\n",
    "#loop to continue executing multiple commands\n",
    "while True:\n",
    "    assistant(myCommand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sizes=[sizex,sizey,sizez]                                    # to give the % size and partitions\n",
    "\n",
    "plt.axis(\"equal\")                                  # to make graph eual form all side\n",
    "\n",
    "labels=['Positive','Negative','Neutral']          # to give the labesl to sections\n",
    "\n",
    "colors=['yellow','red','green']          # to fill diff colors\n",
    "\n",
    "explode=[0.05,0.03,0.06]                              # to highlight a section , (couterclock) used to rotate anticlock wise\n",
    "\n",
    "plt.title(\"Sentiment Analysis\",fontsize=30)                 # to give the title , (autopct) used for give the data in sections\n",
    "\n",
    "plt.pie(sizes,colors=colors,labels=labels,explode=explode,autopct='%.1f%%',startangle=30,counterclock=False)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms=['SVC','LG','MNB','RFC']\n",
    "Acuracy=[Ac_svc,Ac_LG,Ac_nb,Ac_rfc]\n",
    "plt.ylabel('Accuracy',color='black',fontsize=25) \n",
    "plt.xlabel('Algorithms',color='black',fontsize=25)\n",
    "\n",
    "plt.title('Sentiment Score',color='black',fontsize=30)   \n",
    "#plt.plot(x['rollno'],x['cgpa'],color='blue')\n",
    "plt.bar(algorithms,Acuracy,color=['red','green','yellow','blue'],alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
